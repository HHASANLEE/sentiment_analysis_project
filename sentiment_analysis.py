# -*- coding: utf-8 -*-
"""SENTIMENT_ANALYSIS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NWGfMFmrogW9U4CsxrKAjfdaT0-4n-HB
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
nltk.download('punkt')

df = pd.read_csv('/content/train_data.csv')

df.head()

df.shape

df = df.head(500)
print(df.shape)

df.head()

print(df.columns)

example = df['sentence'][49]
print(example)

tokens = nltk.word_tokenize(example)
tokens[:10]

nltk.download('averaged_perceptron_tagger_eng')
nltk.pos_tag(tokens)

tagged = nltk.pos_tag(tokens)
tagged[:10]

nltk.download('maxent_ne_chunker')
nltk.download('words')
nltk.download('maxent_ne_chunker_tab')
entities = nltk.chunk.ne_chunk(tagged)
entities.pprint()

# VADER(Valence Aware Dictionary and sEntiment Reasoner) - Bag of words approach
from nltk.sentiment import SentimentIntensityAnalyzer
from tqdm.notebook import tqdm
nltk.download('vader_lexicon')
sia = SentimentIntensityAnalyzer()

sia.polarity_scores('You are very beautiful')

sia.polarity_scores('example')
#example = sentiment49

#Run the polarity score on the entire dataset
res = {}
for i, row in tqdm(df.iterrows(), total=len(df)):
  Sentence = row['sentence']
  myid = i
  res[myid] = sia.polarity_scores(Sentence)

res

pd.DataFrame(res).T

vaders = pd.DataFrame(res).T
vaders = vaders.merge(df, left_index=True, right_index=True, how='left')

vaders.head()

print(vaders.columns)
print(df.columns)

ax = sns.barplot(data=vaders, x='sentence', y='compound')
ax.set_title('Compound Score by Sentence')
plt.show()

ax = sns.barplot(data=vaders.head(10), x='sentence', y='compound')
ax.set_title('Compound Score by Sentence')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

fig, axs = plt.subplots(1, 3, figsize=(15, 5))
sns.barplot(data=vaders, x='sentence', y='pos', ax=axs[0])
sns.barplot(data=vaders, x='sentence', y='neu', ax=axs[1])
sns.barplot(data=vaders, x='sentence', y='neg', ax=axs[2])
axs[0].set_title('Positive')
axs[1].set_title('Neutral')
axs[2].set_title('Negative')
plt.tight_layout()
plt.show()

from transformers import AutoTokenizer
from transformers import AutoModelForSequenceClassification
from scipy.special import softmax

MODEL = f"cardiffnlp/twitter-roberta-base-sentiment-latest"
tokenizer = AutoTokenizer.from_pretrained(MODEL)
model = AutoModelForSequenceClassification.from_pretrained(MODEL)

#VADER results on example
print(example)
sia.polarity_scores(example)

tokenizer(example, return_tensors='pt')

#run for roBERTa model
encoded_text = tokenizer(example, return_tensors='pt')
output = model(**encoded_text)
scores = output[0][0].detach().numpy()
scores = softmax(scores)
scores_dict = {
    'roberta_neg' : scores[0],
    'roberta_neu' : scores[1],
    'roberta_pos' : scores[2]
}
print(scores_dict)

def polarity_scores_roberta(example):
  encoded_text = tokenizer(example, return_tensors='pt')
  output = model(**encoded_text)
  scores = output[0][0].detach().numpy()
  scores = softmax(scores)
  scores_dict = {
    'roberta_neg' : scores[0],
    'roberta_neu' : scores[1],
    'roberta_pos' : scores[2]
  }
  return scores_dict
#

res = {}
for i, row in tqdm(df.iterrows(), total=len(df)):
  try:
      Sentence = row['sentence']
      myid = i
      res[myid] = sia.polarity_scores(Sentence)
      vader_result = sia.polarity_scores(Sentence)
      vader_result_rename = {}
      for key, value in vader_result.items():
        vader_result_rename[f"vader_{key}"] = value
      roberta_result = polarity_scores_roberta(Sentence)
      both = {**vader_result_rename, **roberta_result}
  except RuntimeError:
      print(f'Broke for id {myid}')
  res[myid] = both

results_df = pd.DataFrame(res).T
results_df = vaders.merge(df, left_index=True, right_index=True, how='left')

results_df.head()

results_df.columns

#Compare scores between models
sns.pairplot(data=results_df,
             vars=['neg', 'neu', 'pos',
                   'neg', 'neu', 'pos'],
             hue='compound',
             palette='tab10')
plt.show()

#review examples
results_df.query('compound <= 0.1')\
    .sort_values('pos', ascending=False)['sentence_x'].values[0]

results_df.query('compound <= 0.1')\
    .sort_values('neg', ascending=False)['sentence_x'].values[0]

results_df.query('compound <= 0.1')\
    .sort_values('neu', ascending=False)['sentence_x'].values[0]

#EXTRA info: The transformer pipeline
from transformers import pipeline
sentiment_pipeline = pipeline("sentiment-analysis")

sentiment_pipeline('I am good')

sentiment_pipeline('I feel tired')

